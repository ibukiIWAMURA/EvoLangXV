{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sem.logic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_at_index(s, index, replacement):\n",
    "    return s[:index] + replacement + s[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "\n",
    "    def from_string(self, string: str):\n",
    "        self.rules = []\n",
    "        rules_str = string.split(\"\\n\")\n",
    "        for rule_str in rules_str:\n",
    "            if rule_str != \"\\n\":\n",
    "                rule_split = rule_str.split(\" \")\n",
    "                lhs_cat = rule_split[0].split(\"/\")[0]\n",
    "                lhs_sem = rule_split[0].split(\"/\")[1]\n",
    "                rhs = rule_split[2]\n",
    "                rule = {\"lhs\":{\"cat\":lhs_cat, \"sem\":lhs_sem}, \"rhs\":rhs}\n",
    "                self.rules.append(rule)\n",
    "    \n",
    "    def add_rule(self, string: str):\n",
    "        rules_str = string.split(\"\\n\")\n",
    "        for rule_str in rules_str:\n",
    "            if rule_str != \"\\n\":\n",
    "                rule_split = rule_str.split(\" \")\n",
    "                lhs_cat = rule_split[0].split(\"/\")[0]\n",
    "                lhs_sem = rule_split[0].split(\"/\")[1]\n",
    "                rhs = rule_split[2]\n",
    "                rule = {\"lhs\":{\"cat\":lhs_cat, \"sem\":lhs_sem}, \"rhs\":rhs}\n",
    "                self.rules.append(rule)\n",
    "    \n",
    "    def to_string(self):\n",
    "        rules_str = \"\"\n",
    "        for rule in self.rules:\n",
    "            rules_str += f\"{rule['lhs']['cat']}/{rule['lhs']['sem']} -> {rule['rhs']}\\n\"\n",
    "        print(rules_str)\n",
    "\n",
    "    def check_chunk01able(self, str1, str2):\n",
    "        if len(str1) != 3 or len(str2) != 3:\n",
    "            return False\n",
    "\n",
    "        diff_count = 0\n",
    "        for char1, char2 in zip(str1, str2):\n",
    "            if char1 != char2:\n",
    "                diff_count += 1\n",
    "                if not (char1.islower() and char2.islower()):\n",
    "                    return False\n",
    "\n",
    "        return diff_count == 1\n",
    "    \n",
    "    def find_diff_position_for_chunk01(self, str1, str2):\n",
    "        if len(str1) != 3 or len(str2) != 3:\n",
    "            return None\n",
    "\n",
    "        diff_count = 0\n",
    "        diff_index = None\n",
    "        for index, (char1, char2) in enumerate(zip(str1, str2)):\n",
    "            if char1 != char2:\n",
    "                diff_count += 1\n",
    "                diff_index = index\n",
    "                if not (char1.islower() and char2.islower()):\n",
    "                    return None\n",
    "\n",
    "        if diff_count == 1:\n",
    "            if diff_index == 0:\n",
    "                diff_index_sem = 1\n",
    "            if diff_index == 1:\n",
    "                diff_index_sem = 0\n",
    "            if diff_index == 2:\n",
    "                diff_index_sem = 2\n",
    "            return diff_index, diff_index_sem\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def check_chunk02able(self, str1, str2):\n",
    "        if len(str1) != 3 or len(str2) != 3:\n",
    "            return False\n",
    "\n",
    "        diff_count = 0\n",
    "        for char1, char2 in zip(str1, str2):\n",
    "            if char1 != char2:\n",
    "                diff_count += 1\n",
    "                if not ((char1.islower() and char2.isupper()) or (char1.isupper() and char2.islower())):\n",
    "                    return False\n",
    "\n",
    "        return diff_count == 1\n",
    "    \n",
    "    def find_diff_position_for_chunk02(self, str1, str2):\n",
    "        if len(str1) != 3 or len(str2) != 3:\n",
    "            return None, None\n",
    "\n",
    "        diff_count = 0\n",
    "        diff_index = None\n",
    "        upper_in_str = None\n",
    "\n",
    "        for index, (char1, char2) in enumerate(zip(str1, str2)):\n",
    "            if char1 != char2:\n",
    "                diff_count += 1\n",
    "                diff_index = index\n",
    "                if (char1.islower() and char2.isupper()):\n",
    "                    lower_in_str = 0\n",
    "                    upper_in_str = 1\n",
    "                elif (char1.isupper() and char2.islower()):\n",
    "                    lower_in_str = 1\n",
    "                    upper_in_str = 0\n",
    "                else:\n",
    "                    return None, None\n",
    "\n",
    "        if diff_count == 1:\n",
    "            if diff_index == 0:\n",
    "                diff_index_sem = 1\n",
    "            if diff_index == 1:\n",
    "                diff_index_sem = 0\n",
    "            if diff_index == 2:\n",
    "                diff_index_sem = 2\n",
    "            return diff_index, diff_index_sem, upper_in_str, lower_in_str\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def chunk01(self):\n",
    "        rules = self.rules\n",
    "\n",
    "        chuncked_rules = []\n",
    "        new_rules = []\n",
    "\n",
    "        for i in range(len(rules)):\n",
    "            for j in range(i+1, len(rules)):\n",
    "                first_sem = Expression.fromstring(rules[i][\"lhs\"][\"sem\"])\n",
    "                second_sem = Expression.fromstring(rules[j][\"lhs\"][\"sem\"])\n",
    "                first_sentence = rules[i][\"rhs\"]\n",
    "                second_sentence = rules[j][\"rhs\"]\n",
    "                if isinstance(first_sem, ApplicationExpression) & isinstance(second_sem, ApplicationExpression):\n",
    "                    if self.check_chunk01able(first_sentence, second_sentence):\n",
    "                        print(f\"Apply chunk01 for {first_sem}:{first_sentence} and {second_sem}:{second_sentence}\")\n",
    "                        first_sem_elements = [first_sem.pred, first_sem.args[0], first_sem.args[1]]\n",
    "                        second_sem_elements = [second_sem.pred, second_sem.args[0], second_sem.args[1]]\n",
    "\n",
    "                        diff_index, diff_index_sem = self.find_diff_position_for_chunk01(first_sentence, second_sentence)\n",
    "\n",
    "                        chuncked_rules.append(rules[i])\n",
    "                        chuncked_rules.append(rules[j])\n",
    "\n",
    "                        # TODO: variable selection\n",
    "                        if diff_index_sem == 0:\n",
    "                            var = Expression.fromstring(\"X\")\n",
    "                        else:\n",
    "                            var = Expression.fromstring(\"x\")\n",
    "                        first_sem_elements_abstracted = copy.deepcopy(first_sem_elements)\n",
    "                        first_sem_elements_abstracted[diff_index_sem] = var\n",
    "                        new_sem_str = f\"{str(first_sem_elements_abstracted[0])}({str(first_sem_elements_abstracted[1])},{str(first_sem_elements_abstracted[2])})\"\n",
    "\n",
    "                        random_category = random.choice(string.ascii_uppercase)\n",
    "                        new_sen_str = replace_at_index(first_sentence, diff_index, random_category)\n",
    "                        new_rule_0 = {\"lhs\": {\"cat\":\"S\", \"sem\": new_sem_str}, \"rhs\": new_sen_str}\n",
    "\n",
    "                        new_rule_1 = {\"lhs\": {\"cat\":random_category, \"sem\": str(first_sem_elements[diff_index_sem])}, \"rhs\": first_sentence[diff_index]}\n",
    "                        new_rule_2 = {\"lhs\": {\"cat\":random_category, \"sem\": str(second_sem_elements[diff_index_sem])}, \"rhs\": second_sentence[diff_index]}\n",
    "                        new_rules += [new_rule_0] + [new_rule_1] + [new_rule_2]\n",
    "        rules = [rule for rule in rules if rule not in chuncked_rules]\n",
    "        self.rules = rules + new_rules\n",
    "\n",
    "    def chunk02(self):\n",
    "        rules = self.rules\n",
    "\n",
    "        chuncked_rules = []\n",
    "        new_rules = []\n",
    "\n",
    "        for i in range(len(rules)):\n",
    "            for j in range(i+1, len(rules)):\n",
    "                first_sem = Expression.fromstring(rules[i][\"lhs\"][\"sem\"])\n",
    "                second_sem = Expression.fromstring(rules[j][\"lhs\"][\"sem\"])\n",
    "                first_sentence = rules[i][\"rhs\"]\n",
    "                second_sentence = rules[j][\"rhs\"]\n",
    "                if isinstance(first_sem, ApplicationExpression) & isinstance(second_sem, ApplicationExpression):\n",
    "                    if self.check_chunk02able(first_sentence, second_sentence):\n",
    "                        print(f\"Apply chunk02 for {first_sem}:{first_sentence} and {second_sem}:{second_sentence}\")\n",
    "                        first_sem_elements = [first_sem.pred, first_sem.args[0], first_sem.args[1]]\n",
    "                        second_sem_elements = [second_sem.pred, second_sem.args[0], second_sem.args[1]]\n",
    "\n",
    "                        diff_index, diff_index_sem, upper_in_str, lower_in_str = self.find_diff_position_for_chunk02(first_sentence, second_sentence)\n",
    "\n",
    "                        target_position = [i,j][lower_in_str]\n",
    "                        nontarget_position = [i,j][upper_in_str]\n",
    "                        chuncked_rules.append(rules[target_position])\n",
    "\n",
    "                        target_sem = Expression.fromstring(rules[target_position][\"lhs\"][\"sem\"])\n",
    "                        target_sem_elements = [target_sem.pred, target_sem.args[0], target_sem.args[1]]\n",
    "                        target_sentence = rules[target_position][\"rhs\"]\n",
    "                        nontarget_sentence = rules[nontarget_position][\"rhs\"]\n",
    "                        new_rule = {\"lhs\": {\"cat\":nontarget_sentence[diff_index], \"sem\": str(target_sem_elements[diff_index_sem])}, \"rhs\": target_sentence[diff_index]}\n",
    "                        new_rules.append(new_rule)\n",
    "        rules = [rule for rule in rules if rule not in chuncked_rules]\n",
    "        self.rules = rules + new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar()\n",
    "grammar.from_string(\"\"\"S/_l(_j,_m) -> jlm\n",
    "S/_l(_j,_s) -> jls\n",
    "S/_h(_j,_s) -> jhs\n",
    "S/_r(_a,_t) -> art\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lhs': {'cat': 'S', 'sem': '_l(_j,_m)'}, 'rhs': 'jlm'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_l(_j,_s)'}, 'rhs': 'jls'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_h(_j,_s)'}, 'rhs': 'jhs'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_r(_a,_t)'}, 'rhs': 'art'}]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply chunk01 for _l(_j,_m):jlm and _l(_j,_s):jls\n",
      "Apply chunk01 for _l(_j,_s):jls and _h(_j,_s):jhs\n"
     ]
    }
   ],
   "source": [
    "grammar.chunk01()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lhs': {'cat': 'S', 'sem': '_r(_a,_t)'}, 'rhs': 'art'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_l(_j,x)'}, 'rhs': 'jlO'},\n",
       " {'lhs': {'cat': 'O', 'sem': '_m'}, 'rhs': 'm'},\n",
       " {'lhs': {'cat': 'O', 'sem': '_s'}, 'rhs': 's'},\n",
       " {'lhs': {'cat': 'S', 'sem': 'X(_j,_s)'}, 'rhs': 'jNs'},\n",
       " {'lhs': {'cat': 'N', 'sem': '_l'}, 'rhs': 'l'},\n",
       " {'lhs': {'cat': 'N', 'sem': '_h'}, 'rhs': 'h'}]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S/_r(_a,_t) -> art\n",
      "S/_l(_j,x) -> jlO\n",
      "O/_m -> m\n",
      "O/_s -> s\n",
      "S/X(_j,_s) -> jNs\n",
      "N/_l -> l\n",
      "N/_h -> h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar()\n",
    "grammar.from_string(\"\"\"S/_l(_j,_m) -> jlm\n",
    "S/_l(x,_s) -> Nls\n",
    "S/_l(_j,_s) -> jls\n",
    "S/_h(_j,_s) -> jhs\n",
    "S/_r(_a,_t) -> art\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply chunk02 for _l(x,_s):Nls and _l(_j,_s):jls\n"
     ]
    }
   ],
   "source": [
    "grammar.chunk02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lhs': {'cat': 'S', 'sem': '_l(_j,_m)'}, 'rhs': 'jlm'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_l(x,_s)'}, 'rhs': 'Nls'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_h(_j,_s)'}, 'rhs': 'jhs'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_r(_a,_t)'}, 'rhs': 'art'},\n",
       " {'lhs': {'cat': 'N', 'sem': '_j'}, 'rhs': 'j'}]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.add_rule(\"S/X(_j,_s) -> jKs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lhs': {'cat': 'S', 'sem': '_l(_j,_m)'}, 'rhs': 'jlm'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_l(x,_s)'}, 'rhs': 'Nls'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_h(_j,_s)'}, 'rhs': 'jhs'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_r(_a,_t)'}, 'rhs': 'art'},\n",
       " {'lhs': {'cat': 'N', 'sem': '_j'}, 'rhs': 'j'},\n",
       " {'lhs': {'cat': 'S', 'sem': 'X(_j,_s)'}, 'rhs': 'jKs'}]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply chunk02 for _h(_j,_s):jhs and X(_j,_s):jKs\n"
     ]
    }
   ],
   "source": [
    "grammar.chunk02()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lhs': {'cat': 'S', 'sem': '_l(_j,_m)'}, 'rhs': 'jlm'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_l(x,_s)'}, 'rhs': 'Nls'},\n",
       " {'lhs': {'cat': 'S', 'sem': '_r(_a,_t)'}, 'rhs': 'art'},\n",
       " {'lhs': {'cat': 'N', 'sem': '_j'}, 'rhs': 'j'},\n",
       " {'lhs': {'cat': 'S', 'sem': 'X(_j,_s)'}, 'rhs': 'jKs'},\n",
       " {'lhs': {'cat': 'K', 'sem': '_h'}, 'rhs': 'h'}]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S/_l(_j,_m) -> jlm\n",
      "S/_l(x,_s) -> Nls\n",
      "S/_r(_a,_t) -> art\n",
      "N/_j -> j\n",
      "S/X(_j,_s) -> jKs\n",
      "K/_h -> h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar.to_string()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evolangxv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
